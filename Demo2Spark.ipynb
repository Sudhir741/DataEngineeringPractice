{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0aed935e-e892-435d-af21-e86eb6af168d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    ".appName(\"pysparkdemo\") \\\n",
    ".getOrCreate()\n",
    "data = [('James','','Smith','1991-04-01','M',3000),\n",
    "  ('Michael','Rose','','2000-05-19','M',4000),\n",
    "  ('Robert','','Williams','1978-09-05','M',4000),\n",
    "  ('Maria','Anne','Jones','1967-12-01','F',4000),\n",
    "  ('Jen','Mary','Brown','1980-02-17','F',-1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cd08c160-3bfe-4f18-881b-b14c22a16903",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=[\"fname\",\"mname\",\"lname\",\"dob\",\"gender\",\"salary\"]\n",
    "df=spark.createDataFrame(data=data,schema=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cff481d5-ca3a-4a1f-a222-78e76feb45d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- fname: string (nullable = true)\n",
      " |-- mname: string (nullable = true)\n",
      " |-- lname: string (nullable = true)\n",
      " |-- dob: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "37f52fb9-5a98-492c-a8ae-9ae37d9d4d88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[fname: string, mname: string, lname: string, dateofbirth: string, gender: string, salary: bigint]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.withColumnRenamed(\"dob\",\"dateofbirth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "30021914-1316-4a2f-9a7d-0a1d1376d792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+--------+----------+------+------+\n",
      "|  fname|mname|   lname|       dob|gender|salary|\n",
      "+-------+-----+--------+----------+------+------+\n",
      "|  James|     |   Smith|1991-04-01|     M|  3000|\n",
      "|Michael| Rose|        |2000-05-19|     M|  4000|\n",
      "| Robert|     |Williams|1978-09-05|     M|  4000|\n",
      "|  Maria| Anne|   Jones|1967-12-01|     F|  4000|\n",
      "|    Jen| Mary|   Brown|1980-02-17|     F|    -1|\n",
      "+-------+-----+--------+----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2cb8499b-8d0e-43c5-9f14-103fa572af0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "df1=df.select(col(\"fname\").alias(\"firstname\"),col(\"lname\").alias(\"lastname\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e8c75729-d40a-495c-a3b7-dc3cb0d4ea2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+\n",
      "|firstname|lastname|\n",
      "+---------+--------+\n",
      "|    James|   Smith|\n",
      "|  Michael|        |\n",
      "|   Robert|Williams|\n",
      "|    Maria|   Jones|\n",
      "|      Jen|   Brown|\n",
      "+---------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "dbc851cc-51bd-4262-abc6-0c223ba85952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8bc87da3-170c-4b0c-b58f-1881ccef52ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+\n",
      "|  fname|   lname|\n",
      "+-------+--------+\n",
      "|  James|   Smith|\n",
      "|Michael|        |\n",
      "| Robert|Williams|\n",
      "|  Maria|   Jones|\n",
      "|    Jen|   Brown|\n",
      "+-------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"fname\",\"lname\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66be77c5-9a4e-4d8f-92e7-628833038d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa609c7e-c636-4132-8232-dc84b6108e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(*cols).show()\n",
    "df.select([col for col in df.columns]).show()\n",
    "df.select(\"*\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c70060-1152-4eb4-8112-52a109dac00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(df.columns[:3]).show(2)\n",
    "df.select(df.columns[2:3]).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69adc9b4-df98-4ade-b011-4baf55a39a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(('James','','Smith'),\"OH\",\"M\"),\n",
    "  (('Michael','Rose',''),'IN','M'),\n",
    "  (('Robert','','Williams'),'GA','M'),\n",
    "  (('Maria','Anne','Jones'),'CU','F'),\n",
    "  (('Jen','Mary','Brown'),'NY','F')\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0790caa-f227-4fcb-af9b-353c2e73a66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType,StructField, StringType        \n",
    "schema = StructType([\n",
    "    StructField('name', StructType([\n",
    "         StructField('firstname', StringType(), True),\n",
    "         StructField('middlename', StringType(), True),\n",
    "         StructField('lastname', StringType(), True)\n",
    "         ])),\n",
    "     StructField('state', StringType(), True),\n",
    "     StructField('gender', StringType(), True)\n",
    "     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8582ac90-9238-43d1-a12d-d16f5e0e3909",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = spark.createDataFrame(data = data, schema = schema)\n",
    "df2.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dfc750-985b-4f59-b480-ff895d98cac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.show(truncate=False) # shows all columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f0450b-d083-463e-8fa0-c72c0fc6fc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.select(\"name\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c571af74-82a8-47ed-8a81-cac105b5a7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.select(\"name.firstname\",\"name.lastname\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89dd524-bb05-41ec-8ef7-b61282fee493",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.select(\"name.*\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67b5af6-04f8-43cf-b5f1-e336d35cf419",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(df.gender==\"M\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08fb4d3-c1f9-4f1c-8e3b-02b8c2e5a617",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.filter(df2.state==\"OH\").show()\n",
    "df2.filter(df2.state!=\"OH\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac440ec4-7d71-49b8-adef-44290c5d550d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.filter(df2.state.startswith(\"O\")).show()\n",
    "df2.filter(df2.state.endswith(\"N\")).show()\n",
    "df2.filter(df2.state.contains(\"H\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b812fd98-13aa-4c6d-b0f1-8cb4c8adbc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.filter(df2.name.firstname.like(\"%ame%\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e275bba-3df3-4c60-afd9-4cb56dedb6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType,StructField \n",
    "from pyspark.sql.types import StringType, IntegerType, ArrayType\n",
    "\n",
    "# Create SparkSession object\n",
    "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
    "\n",
    "# Create data\n",
    "data = [\n",
    "    ((\"James\",\"\",\"Smith\"),[\"Java\",\"Scala\",\"C++\"],\"OH\",\"M\"),\n",
    "    ((\"Anna\",\"Rose\",\"\"),[\"Spark\",\"Java\",\"C++\"],\"NY\",\"F\"),\n",
    "    ((\"Julia\",\"\",\"Williams\"),[\"CSharp\",\"VB\"],\"OH\",\"F\"),\n",
    "    ((\"Maria\",\"Anne\",\"Jones\"),[\"CSharp\",\"VB\"],\"NY\",\"M\"),\n",
    "    ((\"Jen\",\"Mary\",\"Brown\"),[\"CSharp\",\"VB\"],\"NY\",\"M\"),\n",
    "    ((\"Mike\",\"Mary\",\"Williams\"),[\"Python\",\"VB\"],\"OH\",\"M\")\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c71a968-c05d-4581-9575-a9a8fce78dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create schema        \n",
    "schema = StructType([\n",
    "     StructField('name', StructType([\n",
    "        StructField('firstname', StringType(), True),\n",
    "        StructField('middlename', StringType(), True),\n",
    "         StructField('lastname', StringType(), True)\n",
    "     ])),\n",
    "     StructField('languages', ArrayType(StringType()), True),\n",
    "     StructField('state', StringType(), True),\n",
    "     StructField('gender', StringType(), True)\n",
    " ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718efc2b-0313-49a8-a9c4-5e4473f7d5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe\n",
    "df = spark.createDataFrame(data = data, schema = schema)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a4da77-31d0-4469-b8b7-95b1d37fff38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(df.state==\"OH\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0406ad5d-86e0-42a3-8904-328c4f6cd535",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(df.state!=\"OH\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8dd7c2-3582-41fa-ad44-92fd2a9899c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df.filter(col(\"state\") == \"OH\") \\\n",
    "    .show(truncate=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b82efe6-c102-438a-992e-e6d070deaa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using SQL Expression\n",
    "df.filter(\"gender == 'M'\").show()\n",
    "# For not equal\n",
    "df.filter(\"gender != 'M'\").show()\n",
    "df.filter(\"gender <> 'M'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f79889b-f119-47a6-b1d4-be4ef88be8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter multiple conditions\n",
    "df.filter( (df.state  == \"OH\") & (df.gender  == \"M\") ) \\\n",
    "    .show(truncate=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9986f59e-85ce-43e1-b9cd-3c1c232c68c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter using OR operator\n",
    "df.filter( (df.state  == \"OH\") | (df.gender  == \"M\") ) \\\n",
    "    .show(truncate=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b0bca2-7fb6-4570-ae66-80af31efed1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "li=[\"OH\",\"CA\",\"DE\"]\n",
    "df.filter(df.state.isin(li)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67d8a6b-c24f-48e7-91df-383922680980",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(df.state.startswith(\"N\")).show()\n",
    "df.filter(df.state.endswith(\"H\")).show()\n",
    "df.filter(df.state.contains(\"H\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fb342d-dd9f-4c15-897a-cacaec9dd9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.printSchema()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b007d7-cb68-4db2-9fab-ecc4fc450f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(df.name.lastname.like(\"%il%\")).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7450e01-9e11-4041-baec-460461135376",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import array_contains\n",
    "df.filter(array_contains(df.languages,\"Java\")) \\\n",
    "    .show(truncate=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e76cb5-18a3-4ad3-a6c8-29bd017a7c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "simpleData = [(\"James\",\"Sales\",\"NY\",90000,34,10000), \\\n",
    "    (\"Michael\",\"Sales\",\"NY\",86000,56,20000), \\\n",
    "    (\"Robert\",\"Sales\",\"CA\",81000,30,23000), \\\n",
    "    (\"Maria\",\"Finance\",\"CA\",90000,24,23000), \\\n",
    "    (\"Raman\",\"Finance\",\"CA\",99000,40,24000), \\\n",
    "    (\"Scott\",\"Finance\",\"NY\",83000,36,19000), \\\n",
    "    (\"Jen\",\"Finance\",\"NY\",79000,53,15000), \\\n",
    "    (\"Jeff\",\"Marketing\",\"CA\",80000,25,18000), \\\n",
    "    (\"Kumar\",\"Marketing\",\"NY\",91000,50,21000) \\\n",
    "  ]\n",
    "columns= [\"employee_name\",\"department\",\"state\",\"salary\",\"age\",\"bonus\"]\n",
    "# Create SparkSession\n",
    "\n",
    "df = spark.createDataFrame(data = simpleData, schema = columns)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f3a6f0-c324-4ed2-ac6f-7290894589cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort(\"department\",\"state\").show(truncate=False)\n",
    "df.sort(col(\"department\"),col(\"state\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11354531-3220-44c0-a64f-3dbec4f784be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.orderBy(\"department\",\"state\").show(truncate=False)\n",
    "df.orderBy(col(\"department\"),col(\"state\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4db2980-18d0-43e2-bf34-09d4e0ab76bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort(df.department.asc(),df.state.desc()).show(truncate=False)\n",
    "df.sort(col(\"department\").asc(),col(\"state\").desc()).show(truncate=False)\n",
    "df.orderBy(col(\"department\").asc(),col(\"state\").desc()).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c273ed-4aac-41b4-bca7-aec1624b2d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"EMP\")\n",
    "spark.sql(\"select employee_name,department,state,salary,age,bonus from EMP ORDER BY department asc\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1923835-ee20-4e60-b312-755bbd77d75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupBy(\"department\").sum(\"salary\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e4b66e-57cb-48c5-891a-5e3dd76d2235",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupBy(\"department\").count().show()\n",
    "df.groupBy(\"department\").min(\"salary\").show()\n",
    "df.groupBy(\"department\").max(\"salary\").show()\n",
    "df.groupBy(\"department\").mean( \"salary\").show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4530b4e9-aaad-425c-aeca-8902fd5e2429",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupBy(\"department\",\"state\") \\\n",
    "    .sum(\"salary\",\"bonus\") \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3601424a-ef2c-41f2-9d59-837dc1bef7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql.functions import sum,avg,max\n",
    "\n",
    "# Running more aggregations\n",
    "df.groupBy(\"department\") \\\n",
    "    .agg(sum(\"salary\").alias(\"sum_salary\"), \\\n",
    "         avg(\"salary\").alias(\"avg_salary\"), \\\n",
    "         sum(\"bonus\").alias(\"sum_bonus\"), \\\n",
    "         max(\"bonus\").alias(\"max_bonus\") \\\n",
    "     ) \\\n",
    "    .show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c45b785-43f4-4dcc-b47e-a5f693cc78dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sum,avg,max\n",
    "\n",
    "# Using filter on aggregate data\n",
    "df.groupBy(\"department\") \\\n",
    "    .agg(sum(\"salary\").alias(\"sum_salary\"), \\\n",
    "      avg(\"salary\").alias(\"avg_salary\"), \\\n",
    "      sum(\"bonus\").alias(\"sum_bonus\"), \\\n",
    "      max(\"bonus\").alias(\"max_bonus\")) \\\n",
    "    .where(col(\"sum_bonus\") >= 50000) \\\n",
    "    .show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eea1a10-8aed-4f61-b21e-e748e4340562",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Register DataFrame as a temporary view\n",
    "df.createOrReplaceTempView(\"employees\")\n",
    "\n",
    "# Using SQL Query\n",
    "sql_string = \"\"\"SELECT department,\n",
    "       SUM(salary) AS sum_salary,\n",
    "       AVG(salary) AS avg_salary,\n",
    "       SUM(bonus) AS sum_bonus,\n",
    "       MAX(bonus) AS max_bonus\n",
    "FROM employees\n",
    "GROUP BY department\n",
    "HAVING SUM(bonus) >= 50000\"\"\"\n",
    "\n",
    "# Execute SQL query against the temporary view\n",
    "df2 = spark.sql(sql_string)\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6719c77-44c9-4e2a-93c8-7c9d8b52e813",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
